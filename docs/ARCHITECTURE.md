


# ğŸ—ï¸ DocuChat System Architecture

## Overview
DocuChat is a full-stack web application that enables authenticated users to upload documents, monitor indexing progress, and ask natural language questions answered with citations drawn from their uploaded content.  
The system follows a modular **microservice-inspired architecture** with separate **frontend**, **backend**, **database**, **cache**, and **reverse proxy** layersâ€”all orchestrated with Docker Compose.

---

## ğŸ§© High-Level Components

| Layer | Technology | Description |
|-------|-------------|-------------|
| **Frontend** | React + TypeScript + Vite | SPA with routes for login, upload, and chat. Uses Fetch API for REST calls and WebSocket for progress updates. |
| **Backend** | Django + Django REST Framework + Channels | Exposes APIs for authentication, file upload, chat (RAG), and progress streaming. Integrates with Postgres, Redis, and OpenAI. |
| **Database** | PostgreSQL 16 | Stores user data, document metadata, and embeddings. |
| **Cache / Queue** | Redis 7 | Used for WebSocket progress updates and background job coordination. |
| **LLM Integration** | OpenAI (gpt-4o-mini) | Handles natural language questions and contextual RAG responses. |
| **Reverse Proxy** | NGINX | Serves frontend build and reverse-proxies all `/api` and `/ws` requests to the backend. |
| **Container Orchestration** | Docker Compose | Manages all services (frontend, backend, Postgres, Redis, NGINX). |

---

## âš™ï¸ Backend Architecture

### 1. **API Endpoints**
| Endpoint | Method | Description |
|-----------|---------|-------------|
| `/api/me` | GET | Returns current authenticated user info. |
| `/api/upload` | POST | Accepts PDF/TXT/MD files for indexing. |
| `/api/documents` | GET | Lists all uploaded documents. |
| `/api/chat/ask` | POST | Accepts a user question, retrieves relevant chunks, and calls LLM. |
| `/api/health` | GET | Simple readiness check. |

### 2. **RAG Pipeline**
```text
PDF/TXT/MD Upload
   â†“
Text Extraction
   â†“
Chunking â†’ Token Overlap (600 / 80)
   â†“
Embedding (text-embedding-3-small)
   â†“
Vector Storage (Postgres or In-memory)
   â†“
Top-K Retrieval
   â†“
LLM Prompt â†’ Answer + Citations
````

Each uploaded document is split into overlapping text chunks.
Each chunk is embedded and stored.
During queries, the top K embeddings are retrieved and passed to the LLM for contextual answering.

### 3. **Real-time Progress (WebSocket)**

* The backend emits progress events (e.g., `UPLOAD_STARTED`, `INDEXING_COMPLETE`) over `/ws/progress`.
* The frontend `ProgressStream` component subscribes to updates for visual feedback.

---

## ğŸ” Authentication (OIDC / Mock Mode)

* **OIDC (Keycloak)**: Tokens are validated by Django using `KeycloakOIDCAuthentication`.
* **Mock mode**: For local development (`OIDC_VERIFY=mock`), any Bearer token is accepted.
* Frontend login is handled via a simple password field and stored token in `localStorage`.

---

## ğŸŒ Proxy Topology (NGINX)

```
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚        React Frontend        â”‚
            â”‚   (served by NGINX /index)   â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚  NGINX Reverse Proxy   â”‚
               â”‚ /api/* â†’ backend:8000  â”‚
               â”‚ /ws/*  â†’ backend:8000  â”‚
               â”‚ /       â†’ /usr/share/nginx/html â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ Backend (Django + Channels + DRF)         â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚             â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”´â”€â”€â”€â”€â”
        â”‚ PostgreSQL DB â”‚ â”‚ Redis  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ³ Docker Compose Setup

### `infra/docker-compose.yml`

```yaml
services:
  postgres:
    image: postgres:16
  redis:
    image: redis:7
  backend:
    build: ../backend
    ports: ["8000:8000"]
  nginx:
    image: nginx:1.29
    ports: ["80:80"]
    depends_on:
      - backend
```

Each service runs in its own container and communicates via Dockerâ€™s internal network.

---

## ğŸ§  Data Flow

1. **User Authenticates** â†’ Frontend stores token.
2. **User Uploads File** â†’ Frontend sends to `/api/upload`.
3. **Backend Extracts + Indexes** â†’ Emits progress updates.
4. **Chunks + Embeddings Saved** â†’ In Postgres.
5. **User Asks Question** â†’ `/api/chat/ask` fetches top-K chunks and sends to LLM.
6. **Answer Returned** â†’ With citations.

---

## ğŸ§ª Development & Testing

* Run locally:

  ```bash
  cd infra
  docker compose up --build
  ```
* Access frontend at [http://localhost](http://localhost)
* API directly at [http://localhost:8000/api/health](http://localhost:8000/api/health)

---

## ğŸ“‚ Directory Structure

```
docuchat/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ backend/
â”‚   â”‚   â”œâ”€â”€ settings.py
â”‚   â”‚   â””â”€â”€ urls.py
â”‚   â”œâ”€â”€ manage.py
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â””â”€â”€ services/api.ts
â”‚   â””â”€â”€ vite.config.ts
â”œâ”€â”€ infra/
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â””â”€â”€ nginx.conf
â””â”€â”€ docs/
    â”œâ”€â”€ ARCHITECTURE.md
    â””â”€â”€ adr/
```

---

## âœ… Future Enhancements

* Full OIDC login with redirect flow.
* Role-based access control (user/admin).
* Rate limiting per user.
* Persistent vector DB (e.g., pgvector).
* Streaming LLM responses over WebSocket.

---

## ğŸ“œ References

* ADR-001: Authentication Strategy
* ADR-002: Proxy Topology
* ADR-003: RAG Pipeline Design


